\chapter{Implementation}

\section{Parsers}

\subsection{Recursive Descent Parser}

The first \href{https://github.com/ElektraInitiative/libelektra/commit/3d2d4644cb08e83f0b3305b8aeae546ada52dfe7}{YAML plugin} developed in the course of this thesis used a handwritten recursive descent parser. As already described in “\nameref{sec:state_of_the_art}” this technique is quite popular, since there is a natural correspondence between code and grammar rules. Table~\ref{tab:recursive_descent_correspondence} shows the correspondence between \gls{ABNF} grammar rules and matching C like pseudo-code.

\begin{table}[H]
  \begin{center}
    \begin{tabular}{llp{0.48\textwidth}}
      \toprule
      Grammar & Example & Code\\
      \midrule

      Terminal
      &
      \texttt{{\color{color02} a}
              {\color{color03} \textbf{=}}
              {\color{color07} "a"}}
      &
        \begin{tabminted}[autogobble]{c}
          bool a() {
            bool match = getc(file) == 'a';
            if (!match) putc(file);
            return match;
          }
        \end{tabminted}
      \\

      Sequence
      &
      \texttt{{\color{color02} seq}
              {\color{color03} \textbf{=}}
              {\color{color02} rule1 rule2}}
      &
        \begin{tabminted}[autogobble]{c}
          bool seq() {
            return rule1() && rule2();
          }
        \end{tabminted}
      \\

      Alternative
      &
      \texttt{{\color{color02} seq}
              {\color{color03} \textbf{=}}
              {\color{color02} rule1}
              {\color{color03} /}
              {\color{color02} rule2}}
      &
        \begin{tabminted}[autogobble]{c}
          bool alt() {
            return rule1() || rule2();
          }
        \end{tabminted}
      \\

      \bottomrule
    \end{tabular}
  \end{center}
  \caption{Correspondence between grammar rules and code in a recursive descent parser}
  \label{tab:recursive_descent_correspondence}
\end{table}

\newpage
While Table~\ref{tab:recursive_descent_correspondence} suggest writing a recursive descent parser is trivial, there are many problems that the code above does not take into account:

\begin{description}
  \item [Recognizer Only:] The pseudo-code only implements a recognizer for the language. At the end of the parsing process we only know if the input is part of the language produced by the given grammar or not. Usually we want to \emph{build a data structure}, in our case a \cc{KeySet}, from the given input.

  \item [Error Handling:] The code does not contain any error handling. If a given input contains errors, then the creator or editor wants to know \emph{where these errors occurred}. Otherwise she or he has to check the whole input.

  \item [Left Recursion:] If we translate a left recursive rules such as \code{\color{color02} rule1 \color{color03} \textbf{=} \color{color02} rule1 \color{color03} / \color{color02} rule2} using the correspondences given in Table~\ref{tab:recursive_descent_correspondence}, then the resulting code would never terminate. This is the case, since \code{\color{color02} rule1} calls \code{{\color{color02} rule1}}, which then calls \code{\color{color02} rule1}, and so on an so forth (infinite recursion).
\end{description}

All of the problems above apply regardless of the programming language of the parsing code. Since we implemented the recursive descent parser in C, another issue is the error handling in C itself. The language does not provide a native exception handling mechanism. We therefore used the return value to also transfer the error information between functions. This approach is quite cumbersome, since it basically means that we have to check for an error after each function call.

We used C macros to minimize the code overhead and complexity caused by the error handling. Still, for a very small part of the YAML syntax described in the ABNF grammar of Figure~\ref{cod:abnf_recurive_descent} the parser contained about 374 lines of code (counted with \code{cloc} version 1.72). While smaller feature additions, such as going from support of one key-value pair to multiple key-value pairs \href{https://github.com/ElektraInitiative/libelektra/commit/17aa7a6ea5d9261287104213dcba67f4d0a0fcbc}{were quite straightforward} (\textcolor{Green}{14 additions}, \textcolor{Red}{1 deletion}), other modifications, such as supporting block styles would take considerable more effort.

Since the first steps with a hand-written recursive descent parser showed that this approach takes considerable effort we decided against extending the first prototype. Instead we chose to use an already existing hand-written YAML parser.

\begin{figure}[htbp]
  \centering
  \begin{code-boxed}
    \input{Code/yaml}
  \end{code-boxed}
  \caption{ABNF grammar for a very small regular subset of YAML}
  \label{cod:abnf_recurive_descent}
\end{figure}

The official \href{http://yaml.org}{YAML website} prominently lists known YAML parsers. Since we decided to use C or C++ as programming language – to improve the comparability of the parsers – we are left with three basic options:

\begin{itemize}
  \item Syck (YAML 1.0)
  \item \href{https://github.com/yaml/libyaml}{LibYAML} (YAML 1.1)
  \item \href{https://github.com/jbeder/yaml-cpp}{yaml-cpp} (YAML 1.2)
\end{itemize}

. Out of these options Syck is not actively maintained any more. This leaves only \code{libyaml} and \code{yaml-cpp}. We decided to use \code{yaml-cpp}, since it supports the latest version of YAML (\code{YAML 1.2}). With the help of the library we \href{https://github.com/ElektraInitiative/libelektra/pull/1613}{added the first plugin with full YAML support} called \href{https://www.libelektra.org/plugins/yamlcpp}{YAML CPP} to Elektra.

\subsection{ALL(*) Parser}

The first parser generator we used as part of the thesis was \gls{ANTLR} 4. As we already described in the section “\nameref{sec:state_of_the_art}” ANTLR 4 generates parsing code that uses an adaptive LL algorithm called ALL(*). As target language for the generated parser we used the \href{https://github.com/antlr/antlr4/pull/1210}{C++ target for ANTLR}, which was added to the official repository of ANTLR 4 in 2016.

\subsubsection{Initial Attempt}

One of the first problems we encountered using ANTLR was the significant leading whitespace used to describe the structure of YAML block \glspl{collection}. In YAML increased leading whitespace starts a new child element, while decreasing amount of leading whitespace ends an element. Users of programing languages such as \href{https://www.python.org}{Python} or \href{https://www.haskell.org}{Haskell} should be familiar with this style. Unlike \href{https://docs.python.org/3/reference/grammar.html}{Python’s grammar}, YAML’s reference grammar does not use \code{INDENT} and \code{DETEND} tokens, but uses parameterized BNF productions instead. According to the authors of the YAML specification, this is necessary to describe the indentation rules of YAML~\cite{benevansdot2009yaml}:

\begin{quote}
  Many productions use an explicit indentation level parameter. This is less elegant than Python’s “indent” and “undent” [sic] conceptual tokens. However it is required to formally express YAML’s indentation rules.
\end{quote}

.

We first tried to parse different levels of whitespace using \href{https://github.com/sanssecours/Yan-LR/compare/0b0deae...7d9e64e}{\emph{semantic predicates} and \emph{rule arguments}}~\cite{parr1995antlr}. Semantic predicates allow us to disable certain parts of a grammar dynamically, while we can use rule arguments to specify different amount of whitespace. This approach worked, but only for a constant amount of whitespace. If we tried to specify a different amount of leading spaces in a grammar rule, dependent on the amount of leading whitespace matched in the current rule, then the generated parser would be unable to parse our simple example input.

\subsubsection{Indent \& Detend Tokens}

Since the initial attempt for our ANTLR grammar did not show promising results, we looked at how other ANTLR grammars handle significant whitespace.

Bart Kiers created a \href{https://github.com/antlr/grammars-v4/blob/master/python3/Python3.g4}{ANTLR grammar for Python 3}, which captures the start of a document and newline characters inside the lexer. The grammar then uses application-specific code~\cite[p. 48]{parr2013definitive} to fill a stack with the current amount of indentation and emits \code{INDENT} and \code{DETEND} tokens accordingly. Since this method looked promising, we created a \href{https://github.com/sanssecours/Yan-LR/compare/363be1e...188e5d4}{basic YAML parser that used the same algorithm}. While this approach worked for some YAML documents, we found simple input where the algorithm did not show the expected result. Another problem with this approach are complex lexer rules for YAML scalars. The cause of this problem is that the parameterized BNF rules of the YAML specification do not translate well to the basic lexer syntax used to specify characters and character ranges provided by ANTLR.

\section{Additional Plugins}

While most of the problems of adding a YAML storage plugin deal with the parsing process itself, there are other issues we can handle using additional plugins. Elektra’s plugin system allows us to use multiple plugins in conjunction as part of a so-called \emph{backend} (see also section~“\nameref{sec:plugins}”).

\subsection{Base64}
\label{sec:base64}

One of the first plugins we used to improve the YAML support of Elektra was the \href{https://www.libelektra.org/plugins/base64}{Base64} plugin of Peter Nirschl~\cite{nirschl2018crypto}. The plugin en- and decodes binary values using the Base64 algorithm~\cite{josefsson2006base16}.

Since Elektra supports values containing binary data, we can use the Base64 plugin to encode this data and store it using ASCII values in a YAML file. However, the plugin used a common prefix to mark base64-encoded data. For example, if we want to store the decimal numbers 104 (0x68) and 105 (0x69), then the plugin would encode this values as \code{aGk=} and add the prefix \code{@BASE64}. The resulting value would then be \yaml{"@BASE64aGk="}. In YAML a value should not contain a prefix though. Instead YAML marks base64 encoded data with the tag (data type) \yaml{!!binary}. We therefore need to store the two values above as \yaml{!!binary "aGk="} in a YAML file. For this purpose we added a new mode to the Base64 plugin.

The new \emph{meta mode} uses metadata to mark a key-value pair that contains a base64-encoded value. Instead of a prefix Base64 adds a meta-key \code{type} with the value \code{binary}. Figure~\ref{fig:base64} shows an example, where Elektra uses the Base64 plugin to encode and decode the bytes 0x68 and 0x69 (code points for the ASCII string \yaml{hi}).

We should mention here that we only added support for the Base64 encoded data to the \href{https://www.libelektra.org/plugins/yamlcpp}{YAML CPP} plugin, since we decided to not support tags for our YAML subset (see Section “\nameref{sec:discussion_summary_decision}”).

\begin{figure}
  \centering
    \includegraphics[width=\textwidth]{Base64}
  \caption{The Base64 plugin decodes and encodes binary data}
  \label{fig:base64}
\end{figure}

\subsection{Directory Value}

We already described the problem of storing a value in a non-leaf (directory) \cc{Key} in the Section~“\nameref{sec:mapping_elektra_yaml}”. Since the problem is independent of the parser engine and also relevant to other plugins, we implemented the functionality in a plugin named Directory Value.

The Directory Value plugin adds an additional \cc{Key} with the prefix \yaml{___dirdata} for every non-array \cc{Key} that has children and contains a value in the \code{set} direction (position \code{preset}). For example, for the \cc{KeySet} shown in Figure~\ref{fig:keyset_large}, the plugin adds the \cc{Key}

\begin{itemize}
  \item \code{user/yaml/bloc/\_\_\_dirdata} and
  \item \code{user/yaml/bloc/party/\_\_\_dirdata}
\end{itemize}

. The plugin then moves the data stored in the parent \cc{Key} to the newly created \cc{Key}.

\begin{figure}[H]
  \centering
  \begin{subfigure}[t]{.4\textwidth}
    \includegraphics[width=\linewidth]{KeySetLarge}
    \caption{We use the \cc{KeySet} above as input for the Directory Value plugin at the \code{preset} position.}
    \label{fig:keyset_large}
  \end{subfigure}
  \qquad
  \begin{subfigure}[t]{.48\textwidth}
    \includegraphics[width=\linewidth]{KeySetLargeExtended}
    \caption{The \cc{KeySet} above shows the result of the conversion at the \code{preset} position.}
    \label{fig:keyset_large_extended}
  \end{subfigure}
  \caption{The Directory Value plugin adds data at the position \code{preset} (\ref{fig:keyset_large_extended}) and then restores the original data (\ref{fig:keyset_large}) at the position \code{postget}.}
\end{figure}

In addition the plugin insert a new \cc{Key} for every array parent that stores a (non-binary) value, at the first position of the array. In our example, the plugin adds a new \cc{Key} with the value \code{\_\_\_dirdata: Array Value} at the first position of \code{user/yaml/array}, and increases the index of all other array elements by one.

Figure~\ref{fig:keyset_large_extended} shows the \cc{KeySet} after the whole conversion at the position \code{preset}. This \cc{KeySet} is also the input for the Directory Value plugin at the position \code{postget}.
