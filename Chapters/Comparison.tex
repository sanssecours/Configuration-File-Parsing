\chapter{Comparison}

In the evaluation phase of the work we concentrated on the criteria listed below.

\begin{description}

  \item[Run-time Performance]~\\[0.1cm]
  We used each of the parsing algorithms from the implementation phase and executed them using different input files. In each instance we measured the time it took to finish the parsing process. We repeated this multiple times for each combination of parsing technique and file, so we could determine median execution times. At the end of the phase we determined the fastest parsing code and therefore also answered~\Cref{que:speed}:

  \speed*

  \item[Memory Usage]~\\[0.1cm]
  We determined the memory usage of the different parsing implementation using \href{http://valgrind.org}{Valgrind's} heap profiler \href{http://valgrind.org/docs/manual/ms-manual.html}{Massif}.

  \item[Code Size]~\\[0.1cm]
  We counted the lines of the different implementations using the tool \href{https://github.com/AlDanial/cloc}{cloc}.

  \item[Code Complexity]~\\[0.1cm]
  For the measurement of the code complexity we determined
  \begin{itemize}
    \item the cyclomatic complexity~\cite{mccabe1976complexity}, and
    \item the Halstead complexity measures~\cite{halstead1977elements}
  \end{itemize}
  of the generated code.

  \item[Ease of Extensibility and Composability]~\\[0.1cm]
  Since there is no common way to measure either of this attributes we only looked into them from a more informal point of view. In this part of the evaluation we describe some of the features we found that hinder or enhance the extensibility and composability of the used parsing methods. At this stage we also answer~\Cref{que:closeness}:

  \closeness*

  , and argue why certain parsing libraries allow us to stay closer to the definition of the configuration language.

  \item[Error Reporting]~\\[0.1cm]
  For this subtask we created YAML input files, that contain certain errors. We defined reference error messages that describe the problem in a way that is as user-friendly as possible. We then looked how far we can approximate the ideal messages with the different parsing methods.

  \item[Security Problems]~\\[0.1cm]
  We used a \href{https://en.wikipedia.org/wiki/Fuzzing}{fuzzer} (\href{http://lcamtuf.coredump.cx/afl}{american fuzzy lop}) to test the quality of the generated parsing code.

\end{description}
